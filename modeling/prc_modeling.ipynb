{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2088816-3f1c-4fe7-8d1e-f6263103dec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling.profile_report as report\n",
    "\n",
    "import re\n",
    "import seaborn as sns\n",
    "sns.set(style = 'white')\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "%matplotlib inline\n",
    "import matplotlib.ticker as mtick # For specifying the axes tick format \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# modeling\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import make_scorer, recall_score, log_loss\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d5eaa-5a6a-4d63-ba93-dca8ffdb69ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 데이터준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f4e9e-55fa-4e51-beb5-04a6cec77495",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254b1925-a54d-4abd-aedf-95948d81b7c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prc = pd.read_csv('./모델링시작.csv', encoding = 'euc-kr')\n",
    "# prc.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1a66c0-d0a9-406f-b3f3-78d567b979c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prc = prc.drop(['customer_status'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc4245-962e-4062-baf3-865f1fddb493",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64491090-dbfe-4182-b451-8ad0cc0dc4e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4930, 30) (2113, 30)\n",
      "(4930,) (2113,)\n"
     ]
    }
   ],
   "source": [
    "X = prc.drop(['churn'], axis = 1)\n",
    "y = prc['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.3, stratify = y)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19013c79-a7a5-4213-8c55-f01752f070d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 표준화처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e99e543-8ed8-4918-913b-7e19dd8fb0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'married', 'number_of_dependents',\n",
       "       'number_of_referrals', 'tenure_in_months', 'offer', 'phone_service',\n",
       "       'avg_monthly_long_distance_charges', 'multiple_lines',\n",
       "       'internet_service', 'internet_type', 'avg_monthly_gb_download',\n",
       "       'online_security', 'online_backup', 'device_protection_plan',\n",
       "       'premium_tech_support', 'streaming_tv', 'streaming_movies',\n",
       "       'streaming_music', 'unlimited_data', 'contract', 'paperless_billing',\n",
       "       'payment_method', 'monthly_charge', 'total_charges',\n",
       "       'total_extra_data_charges', 'total_long_distance_charges',\n",
       "       'total_revenue', 'tenure_in_years', 'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05ee9ddc-b2f4-4a38-a31c-d4202f80b4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 금액 칼럼 표준화\n",
    "col = ['tenure_in_months', 'avg_monthly_long_distance_charges', 'monthly_charge', 'total_charges',\n",
    "       'total_extra_data_charges', 'total_long_distance_charges',\n",
    "       'total_revenue']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # 데이터 전처리: 표준점수화하기\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train[col])\n",
    "\n",
    "X_train[col] = ss.transform(X_train[col])\n",
    "X_test[col] = ss.transform(X_test[col]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebbbbfa-35e9-4674-8db4-1acf7e5e2995",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 모델 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "243edd2f-3670-4717-b317-73e79008012e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier(tree_method = 'hist'),\n",
    "    'Support Vector Machine': SVC(probability=True),\n",
    "    'Stacking': StackingClassifier(estimators=[('lr', LogisticRegression()),\n",
    "                                               ('rf', RandomForestClassifier()), \n",
    "                                               ('gb', GradientBoostingClassifier())]),\n",
    "    'Bagging': BaggingClassifier(base_estimator=RandomForestClassifier(), n_estimators=10),\n",
    "    'AdaBoost': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50),\n",
    "    'Voting': VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
    "                                           ('rf', RandomForestClassifier()), \n",
    "                                           ('gb', GradientBoostingClassifier())]),\n",
    "    'LightGBM': LGBMClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df2b498-e8c6-4c55-874d-fb1d9cb19a60",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Without Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05cfc29f-9399-44b7-ad6b-ec41711477ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      1552\n",
      "           1       0.64      0.67      0.66       561\n",
      "\n",
      "    accuracy                           0.81      2113\n",
      "   macro avg       0.76      0.77      0.76      2113\n",
      "weighted avg       0.82      0.81      0.82      2113\n",
      "\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85      1552\n",
      "           1       0.59      0.64      0.61       561\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.73      0.74      0.73      2113\n",
      "weighted avg       0.79      0.79      0.79      2113\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1552\n",
      "           1       0.69      0.59      0.64       561\n",
      "\n",
      "    accuracy                           0.82      2113\n",
      "   macro avg       0.77      0.75      0.76      2113\n",
      "weighted avg       0.81      0.82      0.82      2113\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1552\n",
      "           1       0.70      0.66      0.68       561\n",
      "\n",
      "    accuracy                           0.84      2113\n",
      "   macro avg       0.79      0.78      0.79      2113\n",
      "weighted avg       0.83      0.84      0.83      2113\n",
      "\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      1552\n",
      "           1       0.68      0.66      0.67       561\n",
      "\n",
      "    accuracy                           0.83      2113\n",
      "   macro avg       0.78      0.77      0.78      2113\n",
      "weighted avg       0.83      0.83      0.83      2113\n",
      "\n",
      "\n",
      "Support Vector Machine:\n",
      "Accuracy: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87      1552\n",
      "           1       0.72      0.29      0.41       561\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.76      0.62      0.64      2113\n",
      "weighted avg       0.77      0.78      0.75      2113\n",
      "\n",
      "\n",
      "Stacking:\n",
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1552\n",
      "           1       0.71      0.66      0.69       561\n",
      "\n",
      "    accuracy                           0.84      2113\n",
      "   macro avg       0.79      0.78      0.79      2113\n",
      "weighted avg       0.83      0.84      0.84      2113\n",
      "\n",
      "\n",
      "Bagging:\n",
      "Accuracy: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88      1552\n",
      "           1       0.70      0.59      0.64       561\n",
      "\n",
      "    accuracy                           0.82      2113\n",
      "   macro avg       0.78      0.75      0.76      2113\n",
      "weighted avg       0.82      0.82      0.82      2113\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "Accuracy: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      1552\n",
      "           1       0.58      0.65      0.62       561\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.73      0.74      0.73      2113\n",
      "weighted avg       0.79      0.78      0.79      2113\n",
      "\n",
      "\n",
      "Voting:\n",
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1552\n",
      "           1       0.70      0.65      0.67       561\n",
      "\n",
      "    accuracy                           0.83      2113\n",
      "   macro avg       0.79      0.77      0.78      2113\n",
      "weighted avg       0.83      0.83      0.83      2113\n",
      "\n",
      "\n",
      "LightGBM:\n",
      "Accuracy: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      1552\n",
      "           1       0.69      0.66      0.68       561\n",
      "\n",
      "    accuracy                           0.83      2113\n",
      "   macro avg       0.79      0.78      0.78      2113\n",
      "weighted avg       0.83      0.83      0.83      2113\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate models\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy = round(accuracy.mean(), 2)\n",
    "    \n",
    "    print(f'{model_name}:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# Voting\n",
    "# Stacking\n",
    "# GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c1decd-fd1e-493a-8f4e-d045c1bf629f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Adding K-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cf409b2-6138-48b1-8db4-fefbc9683512",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.839959</td>\n",
       "      <td>0.895493</td>\n",
       "      <td>0.708182</td>\n",
       "      <td>0.676300</td>\n",
       "      <td>0.691165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.829437</td>\n",
       "      <td>0.872018</td>\n",
       "      <td>0.732087</td>\n",
       "      <td>0.587782</td>\n",
       "      <td>0.636226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>0.827036</td>\n",
       "      <td>0.868865</td>\n",
       "      <td>0.728176</td>\n",
       "      <td>0.583543</td>\n",
       "      <td>0.629640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.832211</td>\n",
       "      <td>0.864247</td>\n",
       "      <td>0.708894</td>\n",
       "      <td>0.639592</td>\n",
       "      <td>0.671473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.823124</td>\n",
       "      <td>0.862066</td>\n",
       "      <td>0.724390</td>\n",
       "      <td>0.570464</td>\n",
       "      <td>0.617547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.824701</td>\n",
       "      <td>0.855983</td>\n",
       "      <td>0.716993</td>\n",
       "      <td>0.587451</td>\n",
       "      <td>0.630833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.829817</td>\n",
       "      <td>0.855492</td>\n",
       "      <td>0.704448</td>\n",
       "      <td>0.637292</td>\n",
       "      <td>0.668332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.821569</td>\n",
       "      <td>0.837169</td>\n",
       "      <td>0.686997</td>\n",
       "      <td>0.628150</td>\n",
       "      <td>0.655519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.808522</td>\n",
       "      <td>0.649633</td>\n",
       "      <td>0.633933</td>\n",
       "      <td>0.643558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.827647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720872</td>\n",
       "      <td>0.594201</td>\n",
       "      <td>0.637961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.829651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722681</td>\n",
       "      <td>0.601038</td>\n",
       "      <td>0.643817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Algorithm  Accuracy   ROC AUC  Precision    Recall  f1 Score\n",
       "0      Logistic Regression  0.839959  0.895493   0.708182  0.676300  0.691165\n",
       "7                  Bagging  0.829437  0.872018   0.732087  0.587782  0.636226\n",
       "6                 Stacking  0.827036  0.868865   0.728176  0.583543  0.629640\n",
       "4                  XGBoost  0.832211  0.864247   0.708894  0.639592  0.671473\n",
       "5   Support Vector Machine  0.823124  0.862066   0.724390  0.570464  0.617547\n",
       "8                 AdaBoost  0.824701  0.855983   0.716993  0.587451  0.630833\n",
       "3        Gradient Boosting  0.829817  0.855492   0.704448  0.637292  0.668332\n",
       "2            Random Forest  0.821569  0.837169   0.686997  0.628150  0.655519\n",
       "1            Decision Tree  0.811765  0.808522   0.649633  0.633933  0.643558\n",
       "9                   Voting  0.827647       NaN   0.720872  0.594201  0.637961\n",
       "10                LightGBM  0.829651       NaN   0.722681  0.601038  0.643817"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = [] # 각 모델 이름 리스트\n",
    "acc_results = [] # 검증세트 정확도 점수 저장할 리스트 생성\n",
    "auc_results = []\n",
    "pre_results = []\n",
    "rec_results = []\n",
    "f1_results = []\n",
    "\n",
    "result_col = [\"Algorithm\", \"Accuracy\", \"ROC AUC\", \"Precision\", \"Recall\", \"f1 Score\"] # 데이터 프레임 칼럼 리스트\n",
    "model_results = pd.DataFrame(columns = result_col) # 데이터 프레임 생성, 칼럼은 상위 칼럼 리스트\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "i=0\n",
    "for model_name, model in models.items():\n",
    "    model_names.append(model_name)\n",
    "    kf = KFold(n_splits = 5)\n",
    "    \n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kf, scoring = 'accuracy')\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train, cv = kf, scoring = 'roc_auc')\n",
    "    cv_pre_results = model_selection.cross_val_score(model, X_train, y_train, cv = kf, scoring = 'precision')\n",
    "    cv_rec_results = model_selection.cross_val_score(model, X_train, y_train, cv = kf, scoring = 'recall')\n",
    "    cv_f1_results = model_selection.cross_val_score(model, X_train, y_train, cv = kf, scoring = 'f1')\n",
    "\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    pre_results.append(cv_pre_results)\n",
    "    rec_results.append(cv_rec_results)\n",
    "    f1_results.append(cv_f1_results)\n",
    "    \n",
    "    model_results.loc[i] = [model_name,\n",
    "                            np.mean(acc_results),\n",
    "                            np.mean(auc_results),\n",
    "                            np.mean(pre_results),\n",
    "                            np.mean(rec_results),\n",
    "                            np.mean(f1_results)]\n",
    "\n",
    "    i+=1\n",
    "\n",
    "model_results.sort_values(by = ['ROC AUC'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39add07",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28847be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy  0.958\n",
      "Testing accuracy  0.833\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "pred_train_lgbm = lgbm.predict(X_train)\n",
    "pred_test_lgbm = lgbm.predict(X_test)\n",
    "\n",
    "acc_train_lgbm = accuracy_score(pred_train_lgbm, y_train)\n",
    "acc_test_lgbm = accuracy_score(pred_test_lgbm, y_test)\n",
    "\n",
    "print(f'Training accuracy {acc_train_lgbm: .3f}') \n",
    "print(f'Testing accuracy {acc_test_lgbm: .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44afc6f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Train score: 0.911156186612576\n",
      "Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "Best estimator:  LGBMClassifier(max_depth=3, n_estimators=300)\n",
      "Best score:  0.8539553752535497\n",
      "\n",
      "ROC_AUC\n",
      "Train score: 0.9369717762839055\n",
      "Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best estimator:  LGBMClassifier(max_depth=3)\n",
      "Best score:  0.9117693876090017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LGBMClassifier(max_depth=3, n_estimators=300), LGBMClassifier(max_depth=3))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "\n",
    "def tuning_params(X, y, params, model):\n",
    "    gs_acc = GridSearchCV(model, params, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "    gs_auc = GridSearchCV(model, params, scoring = 'roc_auc', cv = 5, n_jobs = -1)\n",
    "    \n",
    "    gs_acc.fit(X, y)\n",
    "    gs_auc.fit(X, y)\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print('Train score:', gs_acc.score(X_train, y_train))\n",
    "    print('Best params:', gs_acc.best_params_)\n",
    "    print(\"Best estimator: \", gs_acc.best_estimator_)\n",
    "    print(\"Best score: \", gs_acc.best_score_)\n",
    "    \n",
    "    print('\\nROC_AUC')\n",
    "    print('Train score:', gs_auc.score(X_train, y_train))\n",
    "    print('Best params:', gs_auc.best_params_)\n",
    "    print(\"Best estimator: \", gs_auc.best_estimator_)\n",
    "    print(\"Best score: \", gs_auc.best_score_)\n",
    "    \n",
    "    return gs_acc.best_estimator_, gs_auc.best_estimator_\n",
    "\n",
    "\n",
    "param1 = [{'n_estimators': [100, 300, 500, 700],\n",
    "           'learning_rate': [0.1, 0.2, 0.3],\n",
    "           'max_depth': [1, 3, 5, 7, 9]}]\n",
    "tuning_params(X_train, y_train, params = param1, model = lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae8a4bc",
   "metadata": {},
   "source": [
    "Accuracy\n",
    "Train score: 0.911156186612576\n",
    "Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
    "Best estimator:  LGBMClassifier(max_depth=3, n_estimators=300)\n",
    "Best score:  0.8539553752535497\n",
    "\n",
    "ROC_AUC\n",
    "Train score: 0.9369717762839055\n",
    "Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
    "Best estimator:  LGBMClassifier(max_depth=3)\n",
    "Best score:  0.9117693876090017\n",
    "\n",
    "(LGBMClassifier(max_depth=3, n_estimators=300), LGBMClassifier(max_depth=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33a52826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on test data: \n",
      "Test accuracy =  0.8381\n",
      "Test precision =  0.7017\n",
      "Test recall =  0.6791\n",
      "Test auc =  0.7874\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      1552\n",
      "           1       0.70      0.68      0.69       561\n",
      "\n",
      "    accuracy                           0.84      2113\n",
      "   macro avg       0.79      0.79      0.79      2113\n",
      "weighted avg       0.84      0.84      0.84      2113\n",
      "\n",
      "Confusion matrix (Rows actual, Columns predicted):\n",
      "      0    1\n",
      "0  1390  162\n",
      "1   180  381\n"
     ]
    }
   ],
   "source": [
    "good_lgbm = LGBMClassifier(learning_rate = 0.1, max_depth = 3, n_estimators = 100)\n",
    "good_lgbm.fit(X_train, y_train)\n",
    "pred_lgbm = good_lgbm.predict(X_test)\n",
    "\n",
    "print('Results on test data: ')\n",
    "\n",
    "acc_lgbm = accuracy_score(y_test, pred_lgbm)\n",
    "pre_lgbm = precision_score(y_test, pred_lgbm)\n",
    "rec_lgbm = recall_score(y_test, pred_lgbm)\n",
    "auc_lgbm = roc_auc_score(y_test, pred_lgbm)\n",
    "\n",
    "print(f'Test accuracy = {acc_lgbm: .4f}') \n",
    "print(f'Test precision = {pre_lgbm: .4f}') \n",
    "print(f'Test recall = {rec_lgbm: .4f}') \n",
    "print(f'Test auc = {auc_lgbm: .4f}')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, pred_lgbm))\n",
    "\n",
    "print(\"Confusion matrix (Rows actual, Columns predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, pred_lgbm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9e7d5",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "339622c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy  1.000\n",
      "Testing accuracy  0.783\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "pred_train_dt = dt.predict(X_train)\n",
    "pred_test_dt = dt.predict(X_test)\n",
    "\n",
    "acc_train_dt = accuracy_score(pred_train_dt, y_train)\n",
    "acc_test_dt = accuracy_score(pred_test_dt, y_test)\n",
    "\n",
    "print(f'Training accuracy {acc_train_dt: .3f}') \n",
    "print(f'Testing accuracy {acc_test_dt: .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c701e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Train score: 0.8446247464503043\n",
      "Best params: {'criterion': 'gini', 'max_depth': 6}\n",
      "Best estimator:  DecisionTreeClassifier(max_depth=6)\n",
      "Best score:  0.8198782961460447\n",
      "\n",
      "ROC_AUC\n",
      "Train score: 0.9107539383009371\n",
      "Best params: {'criterion': 'entropy', 'max_depth': 6}\n",
      "Best estimator:  DecisionTreeClassifier(criterion='entropy', max_depth=6)\n",
      "Best score:  0.8699115498330825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DecisionTreeClassifier(max_depth=6),\n",
       " DecisionTreeClassifier(criterion='entropy', max_depth=6))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "def tuning_params(X, y, params, model):\n",
    "    gs_acc = GridSearchCV(model, params, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "    gs_auc = GridSearchCV(model, params, scoring = 'roc_auc', cv = 5, n_jobs = -1)\n",
    "    \n",
    "    gs_acc.fit(X, y)\n",
    "    gs_auc.fit(X, y)\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print('Train score:', gs_acc.score(X_train, y_train))\n",
    "    print('Best params:', gs_acc.best_params_)\n",
    "    print(\"Best estimator: \", gs_acc.best_estimator_)\n",
    "    print(\"Best score: \", gs_acc.best_score_)\n",
    "    \n",
    "    print('\\nROC_AUC')\n",
    "    print('Train score:', gs_auc.score(X_train, y_train))\n",
    "    print('Best params:', gs_auc.best_params_)\n",
    "    print(\"Best estimator: \", gs_auc.best_estimator_)\n",
    "    print(\"Best score: \", gs_auc.best_score_)\n",
    "    \n",
    "    return gs_acc.best_estimator_, gs_auc.best_estimator_\n",
    "\n",
    "\n",
    "param1 = {'criterion':['gini', 'entropy'], 'max_depth':[None,2,3,4,5,6]}\n",
    "tuning_params(X_train, y_train, params = param1, model = dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c9219",
   "metadata": {},
   "source": [
    "Accuracy\n",
    "Train score: 0.8446247464503043\n",
    "Best params: {'criterion': 'gini', 'max_depth': 6}\n",
    "Best estimator:  DecisionTreeClassifier(max_depth=6)\n",
    "Best score:  0.8198782961460447\n",
    "\n",
    "ROC_AUC\n",
    "Train score: 0.9107539383009371\n",
    "Best params: {'criterion': 'entropy', 'max_depth': 6}\n",
    "Best estimator:  DecisionTreeClassifier(criterion='entropy', max_depth=6)\n",
    "Best score:  0.8699115498330825\n",
    "\n",
    "(DecisionTreeClassifier(max_depth=6),\n",
    " DecisionTreeClassifier(criterion='entropy', max_depth=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97764381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on test data: \n",
      "Test accuracy =  0.8140\n",
      "Test precision =  0.6556\n",
      "Test recall =  0.6310\n",
      "Test auc =  0.7556\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      1552\n",
      "           1       0.66      0.63      0.64       561\n",
      "\n",
      "    accuracy                           0.81      2113\n",
      "   macro avg       0.76      0.76      0.76      2113\n",
      "weighted avg       0.81      0.81      0.81      2113\n",
      "\n",
      "Confusion matrix (Rows actual, Columns predicted):\n",
      "      0    1\n",
      "0  1366  186\n",
      "1   207  354\n"
     ]
    }
   ],
   "source": [
    "good_dt = DecisionTreeClassifier(criterion='entropy', max_depth=6)\n",
    "good_dt.fit(X_train, y_train)\n",
    "pred_dt = good_dt.predict(X_test)\n",
    "\n",
    "print('Results on test data: ')\n",
    "\n",
    "acc_dt = accuracy_score(y_test, pred_dt)\n",
    "pre_dt = precision_score(y_test, pred_dt)\n",
    "rec_dt = recall_score(y_test, pred_dt)\n",
    "auc_dt = roc_auc_score(y_test, pred_dt)\n",
    "\n",
    "print(f'Test accuracy = {acc_dt: .4f}') \n",
    "print(f'Test precision = {pre_dt: .4f}') \n",
    "print(f'Test recall = {rec_dt: .4f}') \n",
    "print(f'Test auc = {auc_dt: .4f}')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, pred_dt))\n",
    "\n",
    "print(\"Confusion matrix (Rows actual, Columns predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, pred_dt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a3a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f7958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3377781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fd0456c-444a-4b9d-b5e9-873c4ba65efc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1819583-a113-42f6-98dd-c1ab6dafa6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pred_train_lr = lr.predict(X_train) # 훈련세트로 예측하기\n",
    "pred_test_lr = lr.predict(X_test) # 테스트세트로 예측하기\n",
    "\n",
    "acc_train_lr = accuracy_score(pred_train_lr, y_train) # 훈련 세트 예측과 훈련 세트 실제 타겟 간의 정확도 확인\n",
    "acc_test_lr = accuracy_score(pred_test_lr, y_test) # 테스트 세트 예측과 테스트 세트 실제 타겟 간의 정확도 확인\n",
    "\n",
    "print(f'Training accuracy {acc_train_lr: .3f}') \n",
    "print(f'Testing accuracy {acc_test_lr: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea328b-6a65-4051-9944-fe97ebab4a10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning the parameters\n",
    "Accuracy<br>\n",
    "Train score: 0.845841784989858<br>\n",
    "Best params: {'C': 10, 'max_iter': 500}<br>\n",
    "Best estimator:  LogisticRegression(C=10, max_iter=500)<br>\n",
    "Best score:  0.8434077079107505<br>\n",
    "<br>\n",
    "ROC_AUC<br>\n",
    "Train score: 0.9024399819654608<br>\n",
    "Best params: {'C': 10, 'max_iter': 900}<br>\n",
    "Best estimator:  LogisticRegression(C=10, max_iter=900)<br>\n",
    "Best score:  0.8982095605726684<br>\n",
    "(LogisticRegression(C=10, max_iter=500),<br>\n",
    " LogisticRegression(C=10, max_iter=900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a50d0-d9ee-4884-9895-1f4791d6a4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "def tuning_params(X, y, params, model):\n",
    "    gs_acc = GridSearchCV(model, params, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "    gs_auc = GridSearchCV(model, params, scoring = 'roc_auc', cv = 5, n_jobs = -1)\n",
    "    \n",
    "    gs_acc.fit(X, y)\n",
    "    gs_auc.fit(X, y)\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print('Train score:', gs_acc.score(X_train, y_train))\n",
    "    print('Best params:', gs_acc.best_params_)\n",
    "    print(\"Best estimator: \", gs_acc.best_estimator_)\n",
    "    print(\"Best score: \", gs_acc.best_score_)\n",
    "    \n",
    "    print('\\nROC_AUC')\n",
    "    print('Train score:', gs_auc.score(X_train, y_train))\n",
    "    print('Best params:', gs_auc.best_params_)\n",
    "    print(\"Best estimator: \", gs_auc.best_estimator_)\n",
    "    print(\"Best score: \", gs_auc.best_score_)\n",
    "    \n",
    "    return gs_acc.best_estimator_, gs_auc.best_estimator_\n",
    "\n",
    "\n",
    "param1 = {'C':[10, 100, 1000], 'max_iter': [100, 300, 500, 700, 900, 1100]}\n",
    "tuning_params(X_train, y_train, params = param1, model = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aad8e53-7450-44a8-8935-5cea35f487f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0bffb-316f-4d39-9c6f-f2e3c132f441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_lr = LogisticRegression(C = 10, max_iter = 900, random_state = 42)\n",
    "good_lr.fit(X_train, y_train)\n",
    "pred_lr = good_lr.predict(X_test)\n",
    "\n",
    "print('Results on test data: ')\n",
    "\n",
    "acc_lr = accuracy_score(y_test, pred_lr)\n",
    "pre_lr = precision_score(y_test, pred_lr)\n",
    "rec_lr = recall_score(y_test, pred_lr)\n",
    "auc_lr = roc_auc_score(y_test, pred_lr)\n",
    "\n",
    "print(f'Test accuracy = {acc_lr: .4f}') \n",
    "print(f'Test precision = {pre_lr: .4f}') \n",
    "print(f'Test recall = {rec_lr: .4f}') \n",
    "print(f'Test auc = {auc_lr: .4f}')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, pred_lr))\n",
    "\n",
    "print(\"Confusion matrix (Rows actual, Columns predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, pred_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36aad6-cc94-4cb4-ac50-917f8dab20f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### memo"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8decf6b7-d981-499d-a56e-dfeaa9efcfdf",
   "metadata": {},
   "source": [
    "print(\"\\nGrid scores:\")\n",
    "meansL = clfL.cv_results_['mean_test_score'] # mean accuracy with folds\n",
    "stdsL = clfL.cv_results_['std_test_score'] # standard deviation of accuracies\n",
    "# for each hyperparameter combination show mean +/- 2 standard-deviations \n",
    "for mean, std, params in zip(meansL, stdsL, clfL.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" %(mean, std * 2, params))\n",
    "    \n",
    "반복문을 통해 \n",
    "각 하이퍼파라미터 조합에 대해 평균 점수와 표준 편차를 출력\n",
    "평균 점수에서 표준 편차의 2배 범위 표시해 성능 측정에 대한 평균값과 분산을 제공\n",
    "모델의 일반화 능력을 추정하는 데 도움이 .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb93b4-7798-48b3-ace1-df41c8b961af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1안\n",
    "# print('\\nROC curve')\n",
    "# plot_roc_curve(good_modelL, X_test, y_test)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# 2안\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test, pred_lr)\n",
    "# roc_auc = metrics.auc(fpr, tpr)\n",
    "# display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Logistic Regression')\n",
    "# display.plot() \n",
    "\n",
    "# 3안\n",
    "# RocCurveDisplay(gb, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff9ac2-7bf0-4983-95e5-49047699b1ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_lr = LogisticRegression(C = 10, max_iter = 500, random_state = 42)\n",
    "good_lr.fit(X_train, y_train)\n",
    "pred_lr = good_lr.predict(X_test)\n",
    "\n",
    "print('Results on test data: ')\n",
    "\n",
    "acc_lr = accuracy_score(y_test, pred_lr)\n",
    "pre_lr = precision_score(y_test, pred_lr)\n",
    "rec_lr = recall_score(y_test, pred_lr)\n",
    "auc_lr = roc_auc_score(y_test, pred_lr)\n",
    "\n",
    "print(f'Test accuracy = {acc_lr: .4f}') \n",
    "print(f'Test precision = {pre_lr: .4f}') \n",
    "print(f'Test recall = {rec_lr: .4f}') \n",
    "print(f'Test auc = {auc_lr: .4f}')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, pred_lr))\n",
    "\n",
    "print(\"Confusion matrix (Rows actual, Columns predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, pred_lr)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5afa1b4-fb1f-4dcd-9e42-fa6ba7fef6ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877defa8-b671-4f51-9614-df0bac9a33e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 순정 테스트\n",
    "bag = BaggingClassifier(base_estimator=RandomForestClassifier(random_state=42), \n",
    "                        random_state = 42, n_jobs = -1)\n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "pred_train_bag = bag.predict(X_train)\n",
    "pred_test_bag = bag.predict(X_test)\n",
    "\n",
    "acc_train_bag = accuracy_score(pred_train_bag, y_train) # 훈련 세트 예측과 훈련 세트 실제 타겟 간의 정확도 확인\n",
    "acc_test_bag = accuracy_score(pred_test_bag, y_test) # 테스트 세트 예측과 테스트 세트 실제 타겟 간의 정확도 확인\n",
    "\n",
    "print(f'Training accuracy {acc_train_rf: .3f}') \n",
    "print(f'Testing accuracy {acc_test_rf: .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0245e-6229-4e6e-b671-e0e3e44163e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bag = BaggingClassifier(base_estimator=RandomForestClassifier(max_features=25, max_leaf_nodes=24, n_estimators=75, random_state=42), \n",
    "                        n_estimators=10, oob_score = True, bootstrap = True, random_state = 42, n_jobs = -1)\n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "pred_train_bag = bag.predict(X_train)\n",
    "pred_test_bag = bag.predict(X_test)\n",
    "\n",
    "acc_train_bag = accuracy_score(pred_train_bag, y_train) # 훈련 세트 예측과 훈련 세트 실제 타겟 간의 정확도 확인\n",
    "acc_test_bag = accuracy_score(pred_test_bag, y_test) # 테스트 세트 예측과 테스트 세트 실제 타겟 간의 정확도 확인\n",
    "\n",
    "print(f'Training accuracy {acc_train_rf: .3f}') \n",
    "print(f'Testing accuracy {acc_test_rf: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e1b89-a8c3-4b89-8aeb-c6cd41c52c38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning the parameters\n",
    "Accuracy <br>\n",
    "Train score: 0.8614604462474645 <br>\n",
    "Best params: {'max_samples': 1000, 'n_estimators': 200} <br>\n",
    "Best estimator:  BaggingClassifier(base_estimator=RandomForestClassifier(max_features=25,\n",
    "                                                        max_leaf_nodes=24,\n",
    "                                                        n_estimators=75,\n",
    "                                                        random_state=42),\n",
    "                  max_samples=1000, n_estimators=200, n_jobs=-1, oob_score=True,\n",
    "                  random_state=42) <br>\n",
    "Best score:  0.8446247464503042 <br>\n",
    " <br>\n",
    "ROC_AUC <br>\n",
    "Train score: 0.9104615947058158 <br>\n",
    "Best params: {'max_samples': 1000, 'n_estimators': 100} <br>\n",
    "Best estimator:  BaggingClassifier(base_estimator=RandomForestClassifier(max_features=25,\n",
    "                                                        max_leaf_nodes=24,\n",
    "                                                        n_estimators=75,\n",
    "                                                        random_state=42),\n",
    "                  max_samples=1000, n_estimators=100, n_jobs=-1, oob_score=True,\n",
    "                  random_state=42) <br>\n",
    "Best score:  0.8911536533705606 <br>\n",
    "(BaggingClassifier(base_estimator=RandomForestClassifier(max_features=25,\n",
    "                                                         max_leaf_nodes=24,\n",
    "                                                         n_estimators=75,\n",
    "                                                         random_state=42),\n",
    "                   max_samples=1000, n_estimators=200, n_jobs=-1, oob_score=True,\n",
    "                   random_state=42), <br>\n",
    " BaggingClassifier(base_estimator=RandomForestClassifier(max_features=25,\n",
    "                                                         max_leaf_nodes=24,\n",
    "                                                         n_estimators=75,\n",
    "                                                         random_state=42),\n",
    "                   max_samples=1000, n_estimators=100, n_jobs=-1, oob_score=True,\n",
    "                   random_state=42)) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6b5fd-54f2-4b91-8c10-f21b51719cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tuning_params(X, y, params, model):\n",
    "    gs_acc = GridSearchCV(model, params, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "    gs_auc = GridSearchCV(model, params, scoring = 'roc_auc', cv = 5, n_jobs = -1)\n",
    "    \n",
    "    gs_acc.fit(X, y)\n",
    "    gs_auc.fit(X, y)\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print('Train score:', gs_acc.score(X_train, y_train))\n",
    "    print('Best params:', gs_acc.best_params_)\n",
    "    print(\"Best estimator: \", gs_acc.best_estimator_)\n",
    "    print(\"Best score: \", gs_acc.best_score_)\n",
    "    \n",
    "    print('\\nROC_AUC')\n",
    "    print('Train score:', gs_auc.score(X_train, y_train))\n",
    "    print('Best params:', gs_auc.best_params_)\n",
    "    print(\"Best estimator: \", gs_auc.best_estimator_)\n",
    "    print(\"Best score: \", gs_auc.best_score_)\n",
    "    \n",
    "    return gs_acc.best_estimator_, gs_auc.best_estimator_\n",
    "\n",
    "# (max_features=25, max_leaf_nodes=24, n_estimators=75, random_state=42)\n",
    "# bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, max_samples=100, n_jobs=-1)\n",
    "# (DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "param1 = [{'n_estimators': [100, 200, 300, 10, 50],\n",
    "          'max_samples': [10, 100, 1000],\n",
    "          }]\n",
    "tuning_params(X_train, y_train, params = param1, model = bag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa884923-fd4e-42a3-89af-2098b61949e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15133cd-b121-40d3-a076-530190bebaee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_bag = BaggingClassifier(base_estimator=RandomForestClassifier(max_features=25, max_leaf_nodes=24, n_estimators=75, random_state=42), \n",
    "                             max_samples=1000, n_estimators=100, n_jobs=-1, oob_score=True, random_state=42)\n",
    "good_bag.fit(X_train, y_train)\n",
    "pred_bag = good_bag.predict(X_test)\n",
    "\n",
    "print('Results on test data: ')\n",
    "\n",
    "acc_bag = accuracy_score(y_test, pred_bag)\n",
    "pre_bag = precision_score(y_test, pred_bag)\n",
    "rec_bag = recall_score(y_test, pred_bag)\n",
    "auc_bag = roc_auc_score(y_test, pred_bag)\n",
    "\n",
    "print(f'Test accuracy = {acc_bag: .4f}') \n",
    "print(f'Test precision = {pre_bag: .4f}') \n",
    "print(f'Test recall = {rec_bag: .4f}') \n",
    "print(f'Test auc = {auc_bag: .4f}')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, pred_bag))\n",
    "\n",
    "print(\"Confusion matrix (Rows actual, Columns predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, pred_bag)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97144328-5ca9-436e-8d52-51038dd9729a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f33e130-d0e8-44a1-8f5e-86348998ef17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pred_train_rf = rf.predict(X_train) # 훈련세트로 예측하기\n",
    "pred_test_rf = rf.predict(X_test) # 테스트세트로 예측하기\n",
    "\n",
    "acc_train_rf = accuracy_score(pred_train_rf, y_train) # 훈련 세트 예측과 훈련 세트 실제 타겟 간의 정확도 확인\n",
    "acc_test_rf = accuracy_score(pred_test_rf, y_test) # 테스트 세트 예측과 테스트 세트 실제 타겟 간의 정확도 확인\n",
    "\n",
    "print(f'Training accuracy {acc_train_rf: .3f}') \n",
    "print(f'Testing accuracy {acc_test_rf: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51dc9d5-133e-470f-b876-ee7cd552e77c",
   "metadata": {},
   "source": [
    "### Tuning the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30e526-abb8-479a-90ab-a13f7e412daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tuning_params(X, y, params, model):\n",
    "    gs_acc = GridSearchCV(model, params, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "    gs_auc = GridSearchCV(model, params, scoring = 'roc_auc', cv = 5, n_jobs = -1)\n",
    "    \n",
    "    gs_acc.fit(X, y)\n",
    "    gs_auc.fit(X, y)\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print('Train score:', gs_acc.score(X_train, y_train))\n",
    "    print('Best params:', gs_acc.best_params_)\n",
    "    print(\"Best estimator: \", gs_acc.best_estimator_)\n",
    "    print(\"Best score: \", gs_acc.best_score_)\n",
    "    \n",
    "    print('\\nROC_AUC')\n",
    "    print('Train score:', gs_auc.score(X_train, y_train))\n",
    "    print('Best params:', gs_auc.best_params_)\n",
    "    print(\"Best estimator: \", gs_auc.best_estimator_)\n",
    "    print(\"Best score: \", gs_auc.best_score_)\n",
    "    \n",
    "    return gs_acc.best_estimator_, gs_auc.best_estimator_\n",
    "\n",
    "param1 = [{'n_estimators': [25, 50, 75],\n",
    "           'max_features': [15, 20, 25],\n",
    "           'max_leaf_nodes': [8, 16, 24]}]\n",
    "tuning_params(X_train, y_train, params = param1, model = rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9de7d1-1a27-4a73-89cc-f8efd9663655",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fcb20-04cf-44d6-a62a-08f40974fdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_rf = RandomForestClassifier(max_features=25, max_leaf_nodes=24, n_estimators=75, random_state=42)\n",
    "\n",
    "good_rf.fit(X_train, y_train)\n",
    "pred_rf = good_rf.predict(X_test)\n",
    "\n",
    "print('Results on test data: ')\n",
    "\n",
    "acc_rf = accuracy_score(y_test, pred_rf)\n",
    "pre_rf = precision_score(y_test, pred_rf)\n",
    "rec_rf = recall_score(y_test, pred_rf)\n",
    "auc_rf = roc_auc_score(y_test, pred_rf)\n",
    "\n",
    "print(f'Test accuracy = {acc_rf: .4f}') \n",
    "print(f'Test precision = {pre_rf: .4f}') \n",
    "print(f'Test recall = {rec_rf: .4f}') \n",
    "print(f'Test auc = {auc_rf: .4f}')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, pred_rf))\n",
    "\n",
    "print(\"Confusion matrix (Rows actual, Columns predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, pred_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c29eb5-c4c5-47a5-b14e-c872b700af67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25d5c7-8cff-4037-a390-30cd96007d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state = 42)\n",
    "scores = cross_validate(gb, X_train, y_train, return_train_score = True, n_jobs = -1) # 교차검증 + 정확도 확인\n",
    "\n",
    "print(\"Train Score:\", np.mean(scores['train_score']))\n",
    "print(\"Test Score:\", np.mean(scores['test_score']))\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "pred_train_gb = gb.predict(X_train)\n",
    "pred_test_gb = gb.predict(X_test)\n",
    "\n",
    "acc_train_gb = accuracy_score(pred_train_gb, y_train)\n",
    "acc_test_gb = accuracy_score(pred_test_gb, y_test)\n",
    "\n",
    "print(f'Training accuracy {acc_train_gb: .3f}') \n",
    "print(f'Testing accuracy {acc_test_gb: .3f}')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b366d09-b004-42d3-bab1-f1d1afef0c91",
   "metadata": {
    "tags": []
   },
   "source": [
    "gb = GradientBoostingClassifier(n_estimators = 500, learning_rate = 0.2, random_state = 42)\n",
    "\n",
    "scores = cross_validate(gb, X_train, y_train, return_train_score = True, n_jobs = -1)\n",
    "\n",
    "print(\"Train Score:\", np.mean(scores['train_score']))\n",
    "print(\"Test Score:\", np.mean(scores['test_score'])) # 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe14133-bbe2-4782-9424-397ef129dcc2",
   "metadata": {},
   "source": [
    "### Tuning the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832ad06-52f2-46cb-84b2-5a8f5c7b1479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tuning_params(X, y, params, model):\n",
    "    gs_acc = GridSearchCV(model, params, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "    gs_auc = GridSearchCV(model, params, scoring = 'roc_auc', cv = 5, n_jobs = -1)\n",
    "    \n",
    "    gs_acc.fit(X, y)\n",
    "    gs_auc.fit(X, y)\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print('Train score:', gs_acc.score(X_train, y_train))\n",
    "    print('Best params:', gs_acc.best_params_)\n",
    "    print(\"Best estimator: \", gs_acc.best_estimator_)\n",
    "    print(\"Best score: \", gs_acc.best_score_)\n",
    "    \n",
    "    print('\\nROC_AUC')\n",
    "    print('Train score:', gs_auc.score(X_train, y_train))\n",
    "    print('Best params:', gs_auc.best_params_)\n",
    "    print(\"Best estimator: \", gs_auc.best_estimator_)\n",
    "    print(\"Best score: \", gs_auc.best_score_)\n",
    "    \n",
    "    return gs_acc.best_estimator_, gs_auc.best_estimator_\n",
    "\n",
    "param1 = [{'n_estimators': [80, 100, 150, 200, 500],\n",
    "         'learning_rate': [0.1, 0.2, 0.3],\n",
    "         'max_depth': [1, 3, 5, 7, 9]}]\n",
    "tuning_params(X_train, y_train, params = param1, model = gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d38d7-e2f1-4644-9754-179d21218184",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### need?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "814fdb78-142d-472c-9b1f-3e8e1da51852",
   "metadata": {
    "tags": []
   },
   "source": [
    "best_index = np.argmax(gs.cv_results_['mean_test_score'])\n",
    "print(np.max(gs.cv_results_['mean_test_score'])) # 가장 높은 검증 정확도 값\n",
    "print(gs.cv_results_['params'][best_index]) # 가장 높은 val_score 평균값 만들때 사용된 params 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0430cd33-22ce-46c0-bb9e-d674ee184d2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b91ddaa-d5c1-4461-9ab3-81743d3d3f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_gb = GradientBoostingClassifier(n_estimators = 300, learning_rate = 0.1, max_depth = 5, random_state = 42)\n",
    "                            # learning_rate GB의 중요한 매개변수. 이전 트리의 오차를 얼마나 강하게 보정할 것인지를 제어\n",
    "                            # n_estimators 트리 더 많이 추가. 모델의 복잡도가 커지고 훈련 세트에서의 실수를 바로 잡을 기회가 더 많아짐\n",
    "\n",
    "good_gb.fit(X_train, y_train)\n",
    "pred_gb = good_gb.predict(X_test)\n",
    "\n",
    "print('Results on test data: ')\n",
    "\n",
    "acc_gb = accuracy_score(y_test, pred_gb)\n",
    "pre_gb = precision_score(y_test, pred_gb)\n",
    "rec_gb = recall_score(y_test, pred_gb)\n",
    "auc_gb = roc_auc_score(y_test, pred_gb)\n",
    "\n",
    "print(f'Test accuracy = {acc_gb: .4f}') \n",
    "print(f'Test precision = {pre_gb: .4f}') \n",
    "print(f'Test recall = {rec_gb: .4f}') \n",
    "print(f'Test auc = {auc_gb: .4f}')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, pred_gb))\n",
    "\n",
    "print(\"Confusion matrix (Rows actual, Columns predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, pred_gb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2575c-a301-42b6-adae-fbb41aae603a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(gb.feature_importances_)\n",
    "print(good_gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c952af4-4129-4eea-9519-cc53dc579e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84448a22-5bc6-4814-8be0-f58b0852bda3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7ecd0-af84-49d4-bc7b-80c6fdb0076b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb =XGBClassifier(tree_method = 'hist', random_state = 42) # (n_estimators=700, learning_rate=0.1, max_depth=3)\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "pred_train_xgb = xgb.predict(X_train)\n",
    "pred_test_xgb = xgb.predict(X_test)\n",
    "\n",
    "acc_train_xgb = accuracy_score(pred_train_xgb, y_train)\n",
    "acc_test_xgb = accuracy_score(pred_test_xgb, y_test)\n",
    "\n",
    "print(f'Training accuracy {acc_train_xgb: .3f}') \n",
    "print(f'Testing accuracy {acc_test_xgb: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abce176-ee7e-4015-8a12-bd08721d615d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tuning the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66141843-38be-4354-a95d-5352ff9611d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tuning_params(X, y, params, model):\n",
    "    gs_acc = GridSearchCV(model, params, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "    gs_auc = GridSearchCV(model, params, scoring = 'roc_auc', cv = 5, n_jobs = -1)\n",
    "    \n",
    "    gs_acc.fit(X, y)\n",
    "    gs_auc.fit(X, y)\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print('Train score:', gs_acc.score(X_train, y_train))\n",
    "    print('Best params:', gs_acc.best_params_)\n",
    "    print(\"Best estimator: \", gs_acc.best_estimator_)\n",
    "    print(\"Best score: \", gs_acc.best_score_)\n",
    "    \n",
    "    print('\\nROC_AUC')\n",
    "    print('Train score:', gs_auc.score(X_train, y_train))\n",
    "    print('Best params:', gs_auc.best_params_)\n",
    "    print(\"Best estimator: \", gs_auc.best_estimator_)\n",
    "    print(\"Best score: \", gs_auc.best_score_)\n",
    "    \n",
    "    return gs_acc.best_estimator_, gs_auc.best_estimator_\n",
    "\n",
    "param1 = [{'n_estimators': [100, 300, 500, 700],\n",
    "           'learning_rate': [0.1, 0.2, 0.3],\n",
    "           'max_depth': [1, 3, 5, 7, 9]}]\n",
    "\n",
    "tuning_params(X_train, y_train, params = param1, model = xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77965e70-49f2-4e13-a6c2-4adc24f34221",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2c5c9-8a37-4699-952e-faa83f4c811f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_xgb = XGBClassifier(tree_method = 'hist', learning_rate = 0.1, max_depth = 3, n_estimators = 500, random_state = 42)\n",
    "\n",
    "evals = [(X_test, y_test)]\n",
    "good_xgb.fit(X_train, y_train, \n",
    "             early_stopping_rounds = 100, eval_metric=\"logloss\", eval_set = evals, verbose=True)\n",
    "pred_xgb = good_xgb.predict(X_test)\n",
    "\n",
    "\n",
    "print('Results on test data: ')\n",
    "\n",
    "acc_xgb = accuracy_score(y_test, pred_xgb)\n",
    "pre_xgb = precision_score(y_test, pred_xgb)\n",
    "rec_xgb = recall_score(y_test, pred_xgb)\n",
    "auc_xgb = roc_auc_score(y_test, pred_xgb)\n",
    "\n",
    "print(f'Test accuracy = {acc_xgb: .4f}') \n",
    "print(f'Test precision = {pre_xgb: .4f}') \n",
    "print(f'Test recall = {rec_xgb: .4f}') \n",
    "print(f'Test auc = {auc_xgb: .4f}')\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, pred_xgb))\n",
    "\n",
    "print(\"Confusion matrix (Rows actual, Columns predicted):\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, pred_xgb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c87882-0085-442b-b5d6-40f5acae4de8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a31c5-4f26-430f-b734-b31d0e122c59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "plot_importance(good_xgb, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e6e44-d3e9-419f-be65-66994017abad",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5dd516d-4e7b-4de5-80b3-a684648ccf39",
   "metadata": {},
   "source": [
    "plot_data(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ee67e-9028-42a7-9a05-95c17aac2345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svmc = SVC(random_state = 42, probability=True)\n",
    "svmc.fit(X_train, y_train)\n",
    "\n",
    "pred_train_svmc = svmc.predict(X_train)\n",
    "pred_test_svmc = svmc.predict(X_test)\n",
    "\n",
    "acc_train_svmc = accuracy_score(pred_train_svmc, y_train)\n",
    "acc_test_svmc = accuracy_score(pred_test_svmc, y_test)\n",
    "\n",
    "print(f'Training accuracy {acc_train_svmc: .3f}') \n",
    "print(f'Testing accuracy {acc_test_svmc: .3f}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11409e14-f11c-4718-b5d3-598ea7f10c30",
   "metadata": {},
   "source": [
    "# SVM, kernel = 'linear'로 선형분리 진행\n",
    "# svm_clf =svm.SVC(kernel = 'linear')\n",
    "\n",
    "print(\"Displaying decision function. Close window to continue.\")  \n",
    "# Plot decision function on training and test data\n",
    "plot_decision_function(X_train, y_train, X_test, y_test, clf)\n",
    "\n",
    "# Make predictions on unseen test data\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e720954-2074-4d64-9244-8f67f441c046",
   "metadata": {},
   "source": [
    "### Tuning the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bf28f-15a6-47ab-be3e-5d07c83cd284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tuning_params(X, y, params, model):\n",
    "    gs_acc = GridSearchCV(model, params, scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "    gs_auc = GridSearchCV(model, params, scoring = 'roc_auc', cv = 5, n_jobs = -1)\n",
    "    \n",
    "    gs_acc.fit(X, y)\n",
    "    gs_auc.fit(X, y)\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print('Train score:', gs_acc.score(X_train, y_train))\n",
    "    print('Best params:', gs_acc.best_params_)\n",
    "    print(\"Best estimator: \", gs_acc.best_estimator_)\n",
    "    print(\"Best score: \", gs_acc.best_score_)\n",
    "    \n",
    "    print('\\nROC_AUC')\n",
    "    print('Train score:', gs_auc.score(X_train, y_train))\n",
    "    print('Best params:', gs_auc.best_params_)\n",
    "    print(\"Best estimator: \", gs_auc.best_estimator_)\n",
    "    print(\"Best score: \", gs_auc.best_score_)\n",
    "    \n",
    "    return gs_acc.best_estimator_, gs_auc.best_estimator_\n",
    "\n",
    "param1 = [{'kernel':['linear', 'rbf'], 'gamma':[1, 0.1, 0, 0.3, 0.5, 0.7], 'C':[1, 10, 100]}]\n",
    "\n",
    "tuning_params(X_train, y_train, params = param1, model = svmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c8254-bacd-4f0b-8f43-2cc4427f203e",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c2f37-a081-4493-beb0-2dc1e0f34953",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 최적 모델 찾기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d6a3887-8610-47e4-a45a-a18c160b9e86",
   "metadata": {},
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(C = 10, max_iter = 900, random_state = 42),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(max_features=25, max_leaf_nodes=24, n_estimators=75, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators = 300, learning_rate = 0.1, max_depth = 5, random_state = 42),\n",
    "    'XGBoost': XGBClassifier(tree_method = 'hist', learning_rate = 0.1, max_depth = 3, n_estimators = 500, random_state = 42),\n",
    "    'Support Vector Machine': SVC(probability=True),\n",
    "    'Stacking': StackingClassifier(estimators=[('lr', LogisticRegression()),\n",
    "                                               ('rf', RandomForestClassifier()), \n",
    "                                               ('gb', GradientBoostingClassifier())]),\n",
    "    'Bagging': BaggingClassifier(base_estimator=RandomForestClassifier(), \n",
    "                        n_estimators=10, oob_score = True, bootstrap = True, random_state = 42, n_jobs = -1),\n",
    "    'AdaBoost': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50),\n",
    "    'Voting': VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
    "                                           ('rf', RandomForestClassifier()), \n",
    "                                           ('gb', GradientBoostingClassifier())])\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf579f29-df97-42b6-bfa4-9e5aa7522016",
   "metadata": {},
   "source": [
    "model_names_opt = [] # 각 모델 이름 리스트\n",
    "acc_results_opt = [] # 검증세트 정확도 점수 저장할 리스트 생성\n",
    "auc_results_opt = []\n",
    "pre_results_opt = []\n",
    "rec_results_opt = []\n",
    "f1_results_opt = []\n",
    "\n",
    "result_col_opt = [\"Algorithm\", \"Accuracy\", \"ROC AUC\", \"Precision\", \"Recall\", \"f1 Score\"] # 데이터 프레임 칼럼 리스트\n",
    "model_results_opt = pd.DataFrame(columns = result_col_opt) # 데이터 프레임 생성, 칼럼은 상위 칼럼 리스트\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "i=0\n",
    "for model_name, model in models.items():\n",
    "    model_names.append(model_name)\n",
    "    kf = KFold(n_splits = 5)\n",
    "    \n",
    "    acc_results_opt = model_selection.cross_val_score(model, X_train, y_train, cv = kf, scoring = 'accuracy')\n",
    "    auc_results_opt = model_selection.cross_val_score(model, X_train, y_train, cv = kf, scoring = 'roc_auc')\n",
    "    pre_results_opt = model_selection.cross_val_score(model, X_train, y_train, cv = kf, scoring = 'precision')\n",
    "    rec_results_opt = model_selection.cross_val_score(model, X_train, y_train, cv = kf, scoring = 'recall')\n",
    "    f1_results_opt = model_selection.cross_val_score(model, X_train, y_train, cv = kf, scoring = 'f1')\n",
    "\n",
    "    acc_results.append(acc_results_opt)\n",
    "    auc_results.append(auc_results_opt)\n",
    "    pre_results.append(pre_results_opt)\n",
    "    rec_results.append(rec_results_opt)\n",
    "    f1_results.append(f1_results_opt)\n",
    "    \n",
    "    model_results.loc[i] = [model_name,\n",
    "                            np.mean(acc_results),\n",
    "                            np.mean(auc_results),\n",
    "                            np.mean(pre_results),\n",
    "                            np.mean(rec_results),\n",
    "                            np.mean(f1_results)]\n",
    "\n",
    "    i+=1\n",
    "\n",
    "model_results.sort_values(by = ['ROC AUC'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fba080",
   "metadata": {},
   "source": [
    "## 고객 이탈을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d346b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고객 데이터 임의 설정\n",
    "gender = 1\n",
    "age = 25\n",
    "married = 0\n",
    "number_of_dependents = 0\n",
    "number_of_referrals = 2\n",
    "tenure_in_months = 7\n",
    "offer = 2\n",
    "phone_service = 0\n",
    "avg_monthly_long_distance_charges = 0\n",
    "multiple_lines = 0\n",
    "internet_service = 1\n",
    "internet_type = 2\n",
    "avg_monthly_gb_download = 45\n",
    "online_security = 1\n",
    "online_backup = 0\n",
    "device_protection_plan = 1\n",
    "premium_tech_support = 0\n",
    "streaming_tv = 1\n",
    "streaming_movies = 0\n",
    "streaming_music = 1\n",
    "unlimited_data = 0\n",
    "contract = 0\n",
    "paperless_billing = 1\n",
    "payment_method = 2\n",
    "monthly_charge = 65\n",
    "total_charges = \n",
    "total_revenue = Total Charges - Total Refurnds + Total Extra Data Charges + Total Lond Distance Charges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
